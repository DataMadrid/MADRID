{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:26.722147Z","iopub.status.busy":"2024-05-21T13:55:26.721861Z","iopub.status.idle":"2024-05-21T13:55:30.646331Z","shell.execute_reply":"2024-05-21T13:55:30.645562Z","shell.execute_reply.started":"2024-05-21T13:55:26.722123Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from torchvision.transforms import v2\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchinfo import summary\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.nn.parallel import DataParallel"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:30.651311Z","iopub.status.busy":"2024-05-21T13:55:30.651054Z","iopub.status.idle":"2024-05-21T13:55:30.674784Z","shell.execute_reply":"2024-05-21T13:55:30.673900Z","shell.execute_reply.started":"2024-05-21T13:55:30.651288Z"},"trusted":true},"outputs":[],"source":["class SegmentationDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None, image_transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.image_transform = image_transform\n","        \n","        self.images = os.listdir(self.image_dir)\n","        self.masks = os.listdir(self.mask_dir)\n","        \n","        # Sort images and masks for consistency\n","        self.images.sort()\n","        self.masks.sort()\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_dir, self.images[idx])\n","        mask_name = os.path.join(self.mask_dir, self.masks[idx])\n","    \n","        image = Image.open(img_name).convert(\"RGB\")\n","        mask = Image.open(mask_name).convert(\"L\") # Convert to grayscale mask\n","    \n","        # Convert the Image object to a numpy array\n","        mask = np.array(mask) / 255.0\n","    \n","        # Now you can perform the comparison\n","        mask = np.where(mask > 0, 1, mask)\n","    \n","        if self.transform:\n","            augmented = self.transform(image=np.array(image), mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","            \n","        if self.image_transform:\n","            # Convert the tensor to a numpy array\n","            image_np = image.cpu().numpy()\n","            # Convert the numpy array back to a PIL Image\n","            image = self.image_transform(image)\n","    \n","        return image, mask\n","\n","\n","common_transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    ToTensorV2()\n","], additional_targets={'image': 'image', 'mask': 'mask'})\n","\n","image_transform = v2.Compose([\n","        v2.ColorJitter(brightness = .5),\n","        v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.5)),\n","        v2.ToDtype(torch.float32, scale=True)\n","])\n","\n","train_image_dir = \"../../images\"\n","train_mask_dir = \"../../masks\"\n","\n","test_image_dir = \"../../images\"\n","test_mask_dir = \"../../masks\"\n","\n","train_dataset = SegmentationDataset(train_image_dir, train_mask_dir, transform=common_transform, image_transform=image_transform)\n","test_dataset = SegmentationDataset(test_image_dir, test_mask_dir, transform=common_transform, image_transform=image_transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:30.675989Z","iopub.status.busy":"2024-05-21T13:55:30.675737Z","iopub.status.idle":"2024-05-21T13:55:44.558074Z","shell.execute_reply":"2024-05-21T13:55:44.556279Z","shell.execute_reply.started":"2024-05-21T13:55:30.675967Z"},"trusted":true},"outputs":[],"source":["def display_images_masks(dataset, start_idx, num_images):\n","    fig, ax = plt.subplots(num_images, 2, figsize=(12, 6*num_images))\n","\n","    for i in range(num_images):\n","        image, mask = dataset[start_idx + i]\n","\n","        # Convert tensors to numpy arrays for visualization\n","        if isinstance(image, torch.Tensor):\n","            image = image.permute(1, 2, 0).numpy()\n","        if isinstance(mask, torch.Tensor):\n","            mask = mask.squeeze().numpy()\n","\n","        ax[i, 0].imshow(image)\n","        ax[i, 0].set_title(f'Image {start_idx + i}')\n","        ax[i, 1].imshow(mask, cmap='gray')\n","        ax[i, 1].set_title(f'Mask {start_idx + i}')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Display the first 10 images and masks from the training dataset\n","display_images_masks(train_dataset, 10, 20)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:44.561164Z","iopub.status.busy":"2024-05-21T13:55:44.560848Z","iopub.status.idle":"2024-05-21T13:55:44.582780Z","shell.execute_reply":"2024-05-21T13:55:44.581881Z","shell.execute_reply.started":"2024-05-21T13:55:44.561137Z"},"trusted":true},"outputs":[],"source":["sample_image, sample_mask = train_dataset[0]\n","print(\"Sample Image Shape:\", sample_image.shape)\n","print(\"Sample Mask Shape:\", sample_mask.shape)\n","print(\"Unique Values in mask:\", np.unique(sample_mask))\n","print(\"Unique Values in image:\", np.unique(sample_image))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:44.584247Z","iopub.status.busy":"2024-05-21T13:55:44.583988Z","iopub.status.idle":"2024-05-21T13:55:44.589979Z","shell.execute_reply":"2024-05-21T13:55:44.589072Z","shell.execute_reply.started":"2024-05-21T13:55:44.584224Z"},"trusted":true},"outputs":[],"source":["len(train_dataset), len(test_dataset),"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:44.591389Z","iopub.status.busy":"2024-05-21T13:55:44.591123Z","iopub.status.idle":"2024-05-21T13:55:44.602181Z","shell.execute_reply":"2024-05-21T13:55:44.601254Z","shell.execute_reply.started":"2024-05-21T13:55:44.591366Z"},"trusted":true},"outputs":[],"source":["sample_image, sample_mask = train_dataset[0]\n","print(\"Sample Image Shape:\", sample_image.shape)\n","print(\"Sample Mask Shape:\", sample_mask.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:44.604060Z","iopub.status.busy":"2024-05-21T13:55:44.603656Z","iopub.status.idle":"2024-05-21T13:55:44.614367Z","shell.execute_reply":"2024-05-21T13:55:44.613406Z","shell.execute_reply.started":"2024-05-21T13:55:44.604028Z"},"trusted":true},"outputs":[],"source":["sample_image, sample_mask = test_dataset[0]\n","print(\"Sample Image Shape:\", sample_image.shape)\n","print(\"Sample Mask Shape:\", sample_mask.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:44.616352Z","iopub.status.busy":"2024-05-21T13:55:44.616017Z","iopub.status.idle":"2024-05-21T13:55:57.018876Z","shell.execute_reply":"2024-05-21T13:55:57.017953Z","shell.execute_reply.started":"2024-05-21T13:55:44.616327Z"},"trusted":true},"outputs":[],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:55:57.020945Z","iopub.status.busy":"2024-05-21T13:55:57.020546Z","iopub.status.idle":"2024-05-21T13:56:03.644597Z","shell.execute_reply":"2024-05-21T13:56:03.643607Z","shell.execute_reply.started":"2024-05-21T13:55:57.020913Z"},"trusted":true},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","\n","aux_params=dict(\n","    classes=1,\n","    dropout=0.2,\n","    activation=None,\n",")\n","\n","model = smp.Unet(\n","    encoder_name=\"resnet152\",  # You can choose different versions of EfficientNet (b0 to b7)\n","    encoder_weights= None,  # Use pre-trained weights if available\n","    in_channels=3,  # Number of input channels (RGB)\n","    aux_params=aux_params,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:03.646748Z","iopub.status.busy":"2024-05-21T13:56:03.645948Z","iopub.status.idle":"2024-05-21T13:56:04.445853Z","shell.execute_reply":"2024-05-21T13:56:04.444916Z","shell.execute_reply.started":"2024-05-21T13:56:03.646713Z"},"trusted":true},"outputs":[],"source":["summary(model,input_size=(64,3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:04.447699Z","iopub.status.busy":"2024-05-21T13:56:04.447287Z","iopub.status.idle":"2024-05-21T13:56:04.476078Z","shell.execute_reply":"2024-05-21T13:56:04.475414Z","shell.execute_reply.started":"2024-05-21T13:56:04.447670Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","batch_size = 32\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Loss and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model = DataParallel(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:04.477510Z","iopub.status.busy":"2024-05-21T13:56:04.477151Z","iopub.status.idle":"2024-05-21T13:56:04.483547Z","shell.execute_reply":"2024-05-21T13:56:04.482665Z","shell.execute_reply.started":"2024-05-21T13:56:04.477476Z"},"trusted":true},"outputs":[],"source":["len(train_loader), len(test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:04.488312Z","iopub.status.busy":"2024-05-21T13:56:04.487960Z","iopub.status.idle":"2024-05-21T13:56:04.493671Z","shell.execute_reply":"2024-05-21T13:56:04.492805Z","shell.execute_reply.started":"2024-05-21T13:56:04.488290Z"},"trusted":true},"outputs":[],"source":["def dice_loss(pred, target, epsilon=1e-6):\n","    intersection = (pred * target).sum()\n","    union = pred.sum() + target.sum()\n","    dice_coeff = (2. * intersection + epsilon) / (union + epsilon)\n","    return 1 - dice_coeff"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:04.495257Z","iopub.status.busy":"2024-05-21T13:56:04.494738Z","iopub.status.idle":"2024-05-21T13:56:04.503229Z","shell.execute_reply":"2024-05-21T13:56:04.502459Z","shell.execute_reply.started":"2024-05-21T13:56:04.495227Z"},"trusted":true},"outputs":[],"source":["import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T13:56:04.504445Z","iopub.status.busy":"2024-05-21T13:56:04.504187Z","iopub.status.idle":"2024-05-21T15:23:43.995585Z","shell.execute_reply":"2024-05-21T15:23:43.994315Z","shell.execute_reply.started":"2024-05-21T13:56:04.504422Z"},"trusted":true},"outputs":[],"source":["losses = []\n","best_loss = float('inf')\n","best_model_wts = copy.deepcopy(model.state_dict())\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, masks in train_loader:\n","        images = images.to(device)\n","        masks = masks.to(device)\n","        \n","        # Forward pass\n","        outputs, _ = model(images)\n","        \n","        # Calculate loss\n","        loss = dice_loss(F.sigmoid(outputs), masks)\n","        losses.append(loss.item())\n","        \n","        # Check if this is the best model\n","        if loss.item() < best_loss:\n","            best_loss = loss.item()\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","        \n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","# Save the best model\n","torch.save(best_model_wts, \"unet_coastline_detection_best.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T15:27:10.778499Z","iopub.status.busy":"2024-05-21T15:27:10.778129Z","iopub.status.idle":"2024-05-21T15:27:18.656268Z","shell.execute_reply":"2024-05-21T15:27:18.655234Z","shell.execute_reply.started":"2024-05-21T15:27:10.778471Z"},"trusted":true},"outputs":[],"source":["# Function to display images, masks, and predictions\n","def visualize_results(model, test_loader, num_images=40):\n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for i, (images, masks) in enumerate(test_loader):\n","            if i >= num_images:\n","                break\n","            \n","            images = images.to(device)\n","            masks = masks.to(device)\n","            \n","            # Forward pass\n","            outputs, _ = model(images)\n","            predicted_masks = torch.sigmoid(outputs)\n","            \n","            images = images.cpu().numpy()\n","            masks = masks.cpu().numpy()\n","            predicted_masks = predicted_masks.cpu().numpy()\n","            \n","            print(masks.shape)\n","            print(images.shape)\n","            \n","            # Convert images to 0-1 range\n","            images = np.transpose(images, (0, 2, 3, 1))\n","            images = (images - np.min(images)) / (np.max(images) - np.min(images))\n","            \n","            # Convert masks to 0-1 range\n","            #masks = np.transpose(masks, (0, 2, 1))  # Corrected this line\n","            predicted_masks = np.transpose(predicted_masks, (0, 2, 3, 1))\n","            \n","            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","            \n","            # Display original image\n","            axes[0].imshow(images[0])\n","            axes[0].set_title(\"Original Image\")\n","            axes[0].axis(\"off\")\n","            \n","            # Display ground truth mask\n","            axes[1].imshow(masks[0].squeeze(), cmap='gray')\n","            axes[1].set_title(\"Ground Truth Mask\")\n","            axes[1].axis(\"off\")\n","            \n","            # Display predicted mask\n","            axes[2].imshow(predicted_masks[0].squeeze(), cmap='gray')\n","            axes[2].set_title(\"Predicted Mask\")\n","            axes[2].axis(\"off\")\n","            \n","            plt.show()\n","\n","# Visualize the model's performance on the test dataset\n","visualize_results(model, test_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T15:25:57.238637Z","iopub.status.busy":"2024-05-21T15:25:57.237890Z","iopub.status.idle":"2024-05-21T15:25:57.247525Z","shell.execute_reply":"2024-05-21T15:25:57.246220Z","shell.execute_reply.started":"2024-05-21T15:25:57.238600Z"},"trusted":true},"outputs":[],"source":["def calculate_metrics(pred, target, threshold=0.5):\n","    pred_binary = (pred > threshold).float()\n","    target_binary = (target > 0.5).float()\n","\n","    intersection = torch.sum(pred_binary * target_binary)\n","    union = torch.sum(pred_binary) + torch.sum(target_binary) - intersection\n","\n","    # Dice Coefficient\n","    dice = (2 * intersection + 1e-6) / (torch.sum(pred_binary) + torch.sum(target_binary) + 1e-6)\n","\n","    # Precision\n","    precision = (intersection + 1e-6) / (torch.sum(pred_binary) + 1e-6)\n","\n","    # Recall\n","    recall = (intersection + 1e-6) / (torch.sum(target_binary) + 1e-6)\n","\n","    # F1 Score\n","    f1_score = 2 * ((precision * recall) / (precision + recall + 1e-6))\n","\n","    # Accuracy\n","    accuracy = torch.sum((pred_binary == target_binary).float()) / target_binary.numel()\n","\n","    return dice.item(), precision.item(), recall.item(), f1_score.item(), accuracy.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T15:26:22.711826Z","iopub.status.busy":"2024-05-21T15:26:22.710805Z","iopub.status.idle":"2024-05-21T15:26:25.339207Z","shell.execute_reply":"2024-05-21T15:26:25.338116Z","shell.execute_reply.started":"2024-05-21T15:26:22.711765Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, test_loader, threshold=0.5):\n","    model.eval()\n","\n","    dice_scores = []\n","    precision_scores = []\n","    recall_scores = []\n","    f1_scores = []\n","    accuracy_scores = []  # Added line\n","\n","    with torch.no_grad():\n","        for images, masks in test_loader:\n","            images = images.to(device)\n","            masks = masks.to(device)\n","\n","            # Forward pass\n","            outputs, _ = model(images)\n","            pred_masks = torch.sigmoid(outputs)\n","\n","            # Calculate metrics\n","            for i in range(images.size(0)):\n","                dice, precision, recall, f1_score, accuracy = calculate_metrics(pred_masks[i], masks[i], threshold)  # Modified line\n","                dice_scores.append(dice)\n","                precision_scores.append(precision)\n","                recall_scores.append(recall)\n","                f1_scores.append(f1_score)\n","                accuracy_scores.append(accuracy)  # Added line\n","\n","    # Calculate average scores\n","    avg_dice = sum(dice_scores) / len(dice_scores)\n","    avg_precision = sum(precision_scores) / len(precision_scores)\n","    avg_recall = sum(recall_scores) / len(recall_scores)\n","    avg_f1_score = sum(f1_scores) / len(f1_scores)\n","    avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)  # Added line\n","\n","    print(f\"Avg Dice Coefficient: {avg_dice:.4f}\")\n","    print(f\"Avg Precision: {avg_precision:.4f}\")\n","    print(f\"Avg Recall: {avg_recall:.4f}\")\n","    print(f\"Avg F1 Score: {avg_f1_score:.4f}\")\n","    print(f\"Avg Accuracy: {avg_accuracy:.4f}\")  # Added line\n","\n","# Evaluate the model on the test dataset\n","evaluate_model(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T15:25:21.541319Z","iopub.status.busy":"2024-05-21T15:25:21.541008Z","iopub.status.idle":"2024-05-21T15:25:22.307345Z","shell.execute_reply":"2024-05-21T15:25:22.306268Z","shell.execute_reply.started":"2024-05-21T15:25:21.541293Z"},"trusted":true},"outputs":[],"source":["a = torch.Tensor(losses).to('cpu')\n","epochs = range(1, len(a) + 1)\n","\n","# Plotting the loss curve\n","plt.figure(figsize=(10, 5))\n","plt.plot(epochs, a, label='Training Loss', color='b')\n","plt.title('Training Loss Curve')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5054427,"sourceId":8475549,"sourceType":"datasetVersion"},{"datasetId":5055855,"sourceId":8477412,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
